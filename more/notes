#Notes:
#ausführen JupyterNotebook Zelle mit shift+enter
#Google AI Studio für Gemini: https://aistudio.google.com/app/api-keys

#LangChain: Werkzeugkasten, um Chatbots zu bauen. Beinhaltet Ketten, Memory, Tools, RAG
#LangChain Webside: ACC anlegen und API-Key erzeugen: https://docs.langchain.com/langsmith/create-account-api-key
#Tutorial: https://python.langchain.com/docs/tutorials/chatbot/

#Kernel: Schnittstelle zwischen Hardware und Anwendersoftware->Verwaltet Prozessor, Arbeitsspeicher, Ein- und AUsgabegeräte,..

#Definition LLM und AI: LLM ist eine bestimmte Untervariante von der AI, das auf Sprachen optimiert ist. Jedes LLM ist eine AI, aber nicht jede AI ist ein LLM
#Prompt: Eingabeaufforderung oder Anweisungen an KI
#API: Application Programming Interface: Schnittstelle zwischen User, Software und dem LLM 
#Graph: Datenstruktur aus Knoten und Verbindungen: User Input → LLM → Tool (z.B. Suche) → LLM → Antwort


#Jetzt: RAG-Ansatz implementieren
#RAG: Retrieval-Augumented Generation [Abruf gestützte Generierung]->Bindet externe Daten in das LLM-Modell ein
       #Chunking: Zerschneiden des Textes
       #word embedding: Text zu Vektor
       #lokalen Vektorstore verwenden: Datenbank für Vektoren mit Metadaten
#Embedding: Sprachmodell "embedded" Text zu Vektor
#Annahme: Vektoren mit ähnlichem Inhalt nah beieinander (Ähnlichkeit wird mit der cosine similarity gemessen)

#Aber warum ist es jetzt noch notwendig, ein RAG einzubinden?
#    ->LLM ist extrem oberflächlich und kennt nur oberflächliche Daten. RAG bringt spezifische Daten in das Modell

#->RAG wird nach der Einagbe des Userprompts eingesetzt, das sucht dann aus den Privaten Quellen sinnvolle Infos. Diese werden dann dem LLM übergeben

